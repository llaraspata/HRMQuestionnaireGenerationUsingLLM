{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prompt Generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook is illustrated how to generate prompts by using the implemented libraries.\n",
    "\n",
    "Note that these prompts are essentially designed for GPT models, or for those supporting the following roles:\n",
    "- **system**,  which provides high-level instructions to guide model’s behavior throughout the conversation;\n",
    "- **user**, it is the model’s response, usually simulated when using few-shot prompting;\n",
    "- **assistant**, that presents queries related to the task the LLM is asked to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('\\\\'.join(os.getcwd().split('\\\\')[:-1])+'\\\\src')\n",
    "\n",
    "import src.data.TFQuestionnairesDataset as tf_qst\n",
    "import src.prompts.PromptGenerator as pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Questionnaire generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of this thesis work is the questionnaire generaion. The designed prompts are reported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# Load data\n",
    "# ----------------\n",
    "dataset = tf_qst.TFQuestionnairesDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **system** prompt has two variants according to the given specifications:\n",
    "1. with all parameters: topic, number and type of questions to be generated\n",
    "2. with only the questionnaire topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_generator = pr.PromptGenerator(\"system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# With all parameters\n",
    "# ----------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
