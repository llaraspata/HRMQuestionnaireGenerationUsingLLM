{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prompt Generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook is illustrated how to generate prompts by using the implemented libraries.\n",
    "\n",
    "Note that these prompts are essentially designed for GPT models, or for those supporting the following roles:\n",
    "- **system**,  which provides high-level instructions to guide model’s behavior throughout the conversation;\n",
    "- **user**, it is the model’s response, usually simulated when using few-shot prompting;\n",
    "- **assistant**, that presents queries related to the task the LLM is asked to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('\\\\'.join(os.getcwd().split('\\\\')[:-1])+'\\\\src')\n",
    "\n",
    "import src.data.TFQuestionnairesDataset as tf_qst\n",
    "import src.prompts.PromptGenerator as pr\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Questionnaire generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of this thesis work is the questionnaire generaion. The designed prompts are reported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# Load data\n",
    "# ----------------\n",
    "dataset = tf_qst.TFQuestionnairesDataset()\n",
    "dataset.load_data()\n",
    "\n",
    "samples = dataset.get_sample_questionnaire_data()\n",
    "question_types = samples.get_question_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *System prompt*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **system** prompt has two variants according to the given specifications:\n",
    "1. with all parameters: topic, number and type of questions to be generated\n",
    "2. with only the questionnaire topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_generator = pr.PromptGenerator(\"system\")\n",
    "\n",
    "with_all_params = system_generator.generate_prompt(has_full_params=True, topic=samples.questionnaires[\"NAME\"], question_type=\"Single choice\", question_nuber=5, \n",
    "                                                   question_types_data=question_types)\n",
    "\n",
    "with_only_topic = system_generator.generate_prompt(has_full_params=False, topic=samples.questionnaires[\"NAME\"], question_types_data=question_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of them are structured as follows:\n",
    "1. **Role definition**, used to define the role the LLM has to impersonate;\n",
    "2. **Input definition**, which define the information that the user can specify and (eventually) the used format;\n",
    "3. **Question types**, used to define the admissible question types;\n",
    "4. **Task definition**, which is used to instruct the LLM on the task it has to perform;\n",
    "5. **Output definition**, it constrates the LLM to use the specified format while generating its response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You are a Questionnaire Generator and you work in the Human Resources '\n",
      " 'Management field. The user will ask you generate surveys mostly.The user has '\n",
      " 'to specify the following elements in the request:\\n'\n",
      " '    - topic\\n'\n",
      " '    - number of questions\\n'\n",
      " '    - type of questions\\n'\n",
      " '\\n'\n",
      " \"The admited question's types are the following:\\n\"\n",
      " '  - ID: 1, CODE: SingleChoice, NAME: Single choice, DESCRIPTION: Use this '\n",
      " 'type of question to choose one answer from a list. \\n'\n",
      " '  - ID: 2, CODE: MultiChoice, NAME: Multi choice, DESCRIPTION: Use this type '\n",
      " 'of question to choose one or more answer from a list. \\n'\n",
      " '  - ID: 3, CODE: RatingScale, NAME: Rating scale, DESCRIPTION: Use this type '\n",
      " 'of question to rate something. \\n'\n",
      " '  - ID: 4, CODE: Comment, NAME: Comment, DESCRIPTION: Use this type of '\n",
      " 'question to aquire feedback. \\n'\n",
      " '  - ID: 5, CODE: ReorderItems, NAME: Reorder items, DESCRIPTION: Use this '\n",
      " 'type of question to reorder items. \\n'\n",
      " '  - ID: 6, CODE: SumDistribution, NAME: Sum distribution, DESCRIPTION: Use '\n",
      " 'this type of question to disribute weights across several items/options. \\n'\n",
      " '  - ID: 7, CODE: Template, NAME: Template, DESCRIPTION: Use this type of '\n",
      " 'question to clone questions from a template. \\n'\n",
      " '  - ID: 8, CODE: DateInput, NAME: Date Input, DESCRIPTION: Use this type of '\n",
      " 'question when the answer to be given is a date or a date/time. \\n'\n",
      " '\\n'\n",
      " 'You must generate a questionnaire according to the user specified '\n",
      " 'characteristics.Your output must respect the following format:\\n'\n",
      " '#TODO\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint(with_all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You are a Questionnaire Generator and you work in the Human Resources '\n",
      " 'Management field. The user will ask you generate surveys mostly.The user has '\n",
      " \"to specify the questionnaire's topic.\\n\"\n",
      " 'Decide the proper numer and type of questions is up to you.\\n'\n",
      " \"The admited question's types are the following:\\n\"\n",
      " '  - ID: 1, CODE: SingleChoice, NAME: Single choice, DESCRIPTION: Use this '\n",
      " 'type of question to choose one answer from a list. \\n'\n",
      " '  - ID: 2, CODE: MultiChoice, NAME: Multi choice, DESCRIPTION: Use this type '\n",
      " 'of question to choose one or more answer from a list. \\n'\n",
      " '  - ID: 3, CODE: RatingScale, NAME: Rating scale, DESCRIPTION: Use this type '\n",
      " 'of question to rate something. \\n'\n",
      " '  - ID: 4, CODE: Comment, NAME: Comment, DESCRIPTION: Use this type of '\n",
      " 'question to aquire feedback. \\n'\n",
      " '  - ID: 5, CODE: ReorderItems, NAME: Reorder items, DESCRIPTION: Use this '\n",
      " 'type of question to reorder items. \\n'\n",
      " '  - ID: 6, CODE: SumDistribution, NAME: Sum distribution, DESCRIPTION: Use '\n",
      " 'this type of question to disribute weights across several items/options. \\n'\n",
      " '  - ID: 7, CODE: Template, NAME: Template, DESCRIPTION: Use this type of '\n",
      " 'question to clone questions from a template. \\n'\n",
      " '  - ID: 8, CODE: DateInput, NAME: Date Input, DESCRIPTION: Use this type of '\n",
      " 'question when the answer to be given is a date or a date/time. \\n'\n",
      " '\\n'\n",
      " 'You must generate a questionnaire according to the user specified '\n",
      " 'characteristics.Your output must respect the following format:\\n'\n",
      " '#TODO\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint(with_only_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Assistant prompt*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **assistant** prompt represents the LLM's output. It's used only when using the *few-shot* prompting technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Questionnaire: \\nTO_BE_PLACED\\n'\n"
     ]
    }
   ],
   "source": [
    "assistant_generator = pr.PromptGenerator(\"assistant\")\n",
    "\n",
    "response = assistant_generator.generate_prompt(json=\"TO_BE_PLACED\")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *User prompt*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **user** prompt reprents the user request. Similarly to the *system* prompt, it has two variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_generator = pr.PromptGenerator(\"user\")\n",
    "\n",
    "with_all_params = user_generator.generate_prompt(has_full_params=True, topic=samples.questionnaires[\"NAME\"], question_type=\"Single choice\", question_nuber=5)\n",
    "with_only_topic = user_generator.generate_prompt(has_full_params=False, topic=samples.questionnaires[\"NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Generate me a questionnaire on Stress Survey with Single choice 5 questions'\n"
     ]
    }
   ],
   "source": [
    "pprint(with_all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Generate me a questionnaire on Stress Survey with Single choice 5 '\n",
      " 'questionsGenerate me a questionnaire on Stress Survey')\n"
     ]
    }
   ],
   "source": [
    "pprint(with_only_topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
